import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

class_names = ['Afghan_hound',
 'African_hunting_dog',
 'Airedale',
 'American_Staffordshire_terrier',
 'Appenzeller',
 'Australian_terrier',
 'Bedlington_terrier',
 'Bernese_mountain_dog',
 'Blenheim_spaniel',
 'Border_collie',
 'Border_terrier',
 'Boston_bull',
 'Bouvier_des_Flandres',
 'Brabancon_griffon',
 'Brittany_spaniel',
 'Cardigan',
 'Chesapeake_Bay_retriever',
 'Chihuahua',
 'Dandie_Dinmont',
 'Doberman',
 'English_foxhound',
 'English_setter',
 'English_springer',
 'EntleBucher',
 'Eskimo_dog',
 'French_bulldog',
 'German_shepherd',
 'German_short-haired_pointer',
 'Gordon_setter',
 'Great_Dane',
 'Great_Pyrenees',
 'Greater_Swiss_Mountain_dog',
 'Ibizan_hound',
 'Irish_setter',
 'Irish_terrier',
 'Irish_water_spaniel',
 'Irish_wolfhound',
 'Italian_greyhound',
 'Japanese_spaniel',
 'Kerry_blue_terrier',
 'Labrador_retriever',
 'Lakeland_terrier',
 'Leonberg',
 'Lhasa',
 'Maltese_dog',
 'Mexican_hairless',
 'Newfoundland',
 'Norfolk_terrier',
 'Norwegian_elkhound',
 'Norwich_terrier',
 'Old_English_sheepdog',
 'Pekinese',
 'Pembroke',
 'Pomeranian',
 'Rhodesian_ridgeback',
 'Rottweiler',
 'Saint_Bernard',
 'Saluki',
 'Samoyed',
 'Scotch_terrier',
 'Scottish_deerhound',
 'Sealyham_terrier',
 'Shetland_sheepdog',
 'Shih-Tzu',
 'Siberian_husky',
 'Staffordshire_bullterrier',
 'Sussex_spaniel',
 'Tibetan_mastiff',
 'Tibetan_terrier',
 'Walker_hound',
 'Weimaraner',
 'Welsh_springer_spaniel',
 'West_Highland_white_terrier',
 'Yorkshire_terrier',
 'affenpinscher',
 'basenji',
 'basset',
 'beagle',
 'black-and-tan_coonhound',
 'bloodhound',
 'bluetick',
 'borzoi',
 'boxer',
 'briard',
 'bull_mastiff',
 'cairn',
 'chow',
 'clumber',
 'cocker_spaniel',
 'collie',
 'curly-coated_retriever',
 'dhole',
 'dingo',
 'flat-coated_retriever',
 'giant_schnauzer',
 'golden_retriever',
 'groenendael',
 'keeshond',
 'kelpie',
 'komondor',
 'kuvasz',
 'malamute',
 'malinois',
 'miniature_pinscher',
 'miniature_poodle',
 'miniature_schnauzer',
 'otterhound',
 'papillon',
 'pug',
 'redbone',
 'schipperke',
 'silky_terrier',
 'soft-coated_wheaten_terrier',
 'standard_poodle',
 'standard_schnauzer',
 'toy_poodle',
 'toy_terrier',
 'vizsla',
 'whippet',
 'wire-haired_fox_terrier']

shiba=torch.tensor([-1.6511,  0.0793, -2.4278,  1.3901,  1.0965, -0.0325, -1.9329, -2.1221,
        -0.8297, -0.5524, -0.1533, -0.1561, -2.5217,  1.1874,  0.8748,  3.7256,
        -1.8092,  4.1403,  1.2130, -2.2246,  0.8432, -2.8392, -2.7302,  0.3537,
         3.7877, -0.0792,  0.0595, -2.0647, -4.5821, -2.0187, -2.4102, -1.5765,
         4.2684, -2.9729,  1.2725, -2.8552, -0.8126,  1.2010, -0.7121, -0.6066,
        -0.8035,  1.2447, -0.2696,  0.5991, -1.4190, -1.3950, -1.6620,  2.7004,
         1.6022,  4.3129, -2.6291, -1.1999,  6.1904,  3.2499, -0.0667, -2.6962,
        -1.8651,  2.6875,  0.6688,  0.4719, -0.3219, -0.7937,  2.4262, -0.5707,
         4.0719,  0.4703, -2.1566, -0.7671,  0.0352, -0.5728, -2.3001, -0.4763,
         0.7916, -0.1818, -1.0862,  6.4710,  0.4964,  2.1456, -3.4746, -2.0169,
        -1.3862,  0.3171, -0.4733, -2.7138, -2.0870,  1.0308,  2.8879, -2.7053,
        -0.9489,  2.7359, -2.5738,  7.3788,  8.0668, -2.6853, -2.9530,  0.1330,
        -0.5273, -1.1907,  2.3482, -2.1499, -1.5992,  2.4567,  1.3275,  0.4351,
         0.6302,  0.6560, -1.2541,  0.8301, -1.5405, -0.1704, -0.3215, -1.1218,
         0.0212, -0.7609, -0.2577, -0.5273,  1.3725, -1.9530,  3.1149,  1.9040])
jack=torch.tensor([-3.4158, -2.0008, -1.6147,  4.7414,  2.2585, -1.1866, -0.7759, -1.1593,
         3.8892,  0.0146,  1.9313,  2.4373, -2.9933,  0.9517,  3.2428,  3.7635,
        -1.5101,  3.2176, -0.4288, -1.9236,  3.0756,  0.7113,  0.3833, -0.3908,
         0.3693,  2.6563, -1.9578, -0.5164, -4.0566,  0.8870,  0.5772,  0.2028,
         4.2946, -2.3197,  1.3297, -3.5745, -0.0701,  2.7631, -0.0870, -0.2264,
         1.3646,  0.7141, -2.2734, -0.0913,  0.5672,  0.5202, -1.7055,  1.6394,
        -1.0989, -0.6664, -2.1533, -1.6529,  2.3057, -1.2046,  0.7732, -2.4450,
         1.8249, -0.4261, -0.7183,  0.7678, -0.9019,  1.5932, -0.7447,  0.7429,
         0.4814,  3.6111, -1.9649, -3.8923, -1.1046,  2.2766, -0.7006,  2.4201,
         1.4047, -1.1004, -1.0877,  3.2306,  0.6731,  3.0482, -3.4609, -2.6104,
        -1.2660,  1.6500,  3.4086, -1.7530,  0.4503,  0.4764, -2.6367,  0.6153,
         0.7873, -0.2407, -1.9414, -1.3690,  0.5048, -2.4875, -0.4692, -0.3678,
        -4.1825, -3.3587, -0.0152, -2.5235,  0.0270, -0.9319, -0.0687,  0.0268,
        -0.3863,  1.9332, -2.4909,  2.2490,  0.6324, -1.2879, -2.1043, -1.5719,
        -1.9432, -0.9173, -0.1429, -0.9562,  4.5871, -0.8505,  4.0448,  2.4620])

marupu=torch.tensor([ 3.5231, -3.6997, -0.1249, -2.3182, -1.9718,  3.3595, -3.7626, -0.9897,
         4.9014, -3.2142,  2.0224, -1.6834,  1.4533,  3.0444, -0.4157, -1.5193,
        -0.6170,  2.6989,  3.2402, -3.4121, -2.3687, -1.2506, -1.7292, -2.9748,
        -4.6110, -2.0694, -4.2044, -2.0134, -1.8193, -3.4655, -1.5860, -1.8671,
        -3.8300,  2.0176,  2.6056, -2.4520, -2.4834, -1.4988,  0.7664,  0.5401,
         0.1110,  0.6912,  1.3399, 10.0715,  6.8955, -2.9209,  1.8593,  8.9983,
        -4.9619,  6.1710, -0.5866,  5.9329, -0.1444,  4.5862,  0.6075, -1.2160,
        -1.2195, -1.5701, -2.5944,  0.2680, -3.1589,  0.8883, -0.5485,  7.4506,
        -2.8419, -0.6921,  3.4182, -1.3874,  5.2317, -2.9390, -3.4794, -1.3227,
         0.9886,  7.8131,  5.4411, -2.2672, -2.3298, -0.0496, -2.4837, -0.2874,
        -2.1851, -4.2920,  0.0710,  4.6110, -1.4875,  4.2418,  0.2673, -1.8959,
         1.9095, -1.4898, -3.5722, -2.3431, -3.9273, -0.4925,  0.2215,  3.3523,
        -4.3577, -2.4576, -3.7855, -0.1783, -3.3834, -3.4631, -3.3724,  0.4426,
         4.2748,  3.7998,  1.9214,  1.2572, -0.9376,  1.3402, -2.1414,  5.0180,
         4.7099, -0.4182,  0.7772,  5.3534, -0.0640, -0.1406, -3.5722, -0.2938])

wasao=torch.tensor([-0.1297, -3.1812, -0.0242,  0.4058, -0.7048, -1.1334, -2.0445,  0.5311,
        -1.5062,  1.7193, -2.5738, -1.8614, -0.0353, -2.4767,  0.3834,  0.2303,
         0.1478, -0.9810, -2.9900, -2.5745, -2.9177, -0.7277, -1.9490, -2.1462,
         4.6645, -0.4833,  1.8758, -2.5245, -3.1776, -1.0610,  5.6470,  0.4428,
        -2.9631, -1.2082, -0.3582, -1.6787,  1.0768, -2.0438, -1.5610, -1.3545,
         1.9402,  0.9844,  1.5454,  0.3539, -1.1637, -2.9447,  4.1340,  0.7659,
         2.0077,  2.7369,  1.7277,  1.0137,  2.5976,  6.5549, -0.5860,  0.0138,
         1.7742, -2.4840,  8.8529, -0.9600, -0.4337, -3.3901,  2.9692, -2.9242,
         4.2750, -0.9173, -0.2615,  4.4713, -1.3206, -1.4151, -0.8289, -0.0467,
         1.3573, -3.5645, -2.0891, -0.4719,  0.0647, -0.6653, -3.4649, -0.9325,
        -1.4717, -0.5117, -1.7755,  0.0711, -1.0127,  0.4695,  9.8821, -1.3245,
         0.5709,  4.0272, -2.2992,  0.1527,  1.5093, -1.5137, -1.7320,  3.1235,
         3.4081,  5.1642,  0.9525,  1.3350,  2.7085,  4.9844, -0.5973, -2.6165,
        -1.3681, -3.3139, -0.2648, -0.6984,  0.5368,  0.1139,  2.5948, -1.6404,
         0.4472,  1.0725, -2.7272,  0.6179, -2.2439, -1.3680, -1.9056, -1.4953])

puu = torch.tensor([-2.7616,  0.9555, -1.5077,  1.1374,  0.3285, -2.6850, -1.8438, -1.8835,
         0.4558,  0.5514,  1.0590,  3.2715, -1.8031,  5.1888,  0.5211, -0.3572,
         0.2682,  0.9625, -2.0025, -2.4851, -1.8871,  0.5694, -0.0195, -1.6536,
         0.6510,  5.3425,  0.1076, -0.8564, -2.7426,  0.8806,  2.2670, -2.1128,
        -3.0649, -3.3187, -1.6182, -2.3804, -0.6019, -1.0084,  2.8194, -0.2776,
         2.6187, -0.8378,  1.5284,  1.7670, -0.6119, -1.2952,  2.4678, -1.6463,
         3.3675, -2.9728, -0.8882,  3.8936, -1.7952, -1.2526, -0.5634,  0.4547,
         2.4446, -1.0523,  0.7354, -0.4944, -3.0337, -1.3567, -1.3249,  2.3948,
         1.4107,  2.6206, -0.6372,  1.9078, -0.3284,  0.1252, -0.6605, -1.9529,
        -0.5617, -3.1824,  1.5484, -1.0330, -1.9289, -0.1138, -2.2352, -0.9570,
         0.0395,  0.4494,  2.5517,  0.5248,  4.7898,  0.3208,  1.2811, -0.0329,
         0.7549,  0.5362, -0.2645, -1.5229, -0.4175,  0.1262,  1.4745,  0.8268,
        -1.7624,  0.8126, -0.7173, -1.8812,  3.6526,  0.4924,  0.4158, -2.0183,
        -0.4999,  0.5778, -3.5465, -0.3676, 10.1556, -1.8822,  0.6221, -1.3583,
        -0.6841,  0.5048, -0.2253, -0.7743,  1.7858, -2.1798,  0.1418, -1.7640])

chiwax=torch.tensor([-1.4581, -2.6754, -0.3198, -0.5483,  1.3198, -0.4940, -1.0371, -1.2834,
         0.2955, -0.2823,  2.9189, -2.7962, -3.2401,  2.6040,  1.3234, -2.1066,
         2.5709,  3.1355,  1.5293, -1.2143,  0.5708,  1.6945, -3.3084,  1.1097,
        -2.3486, -1.5105, -2.6110,  0.6195, -2.0464, -1.0859,  1.9964, -0.4133,
        -2.9706, -0.5107,  0.9455, -3.0265, -1.1337, -0.7305,  0.1624, -1.2060,
         6.6882,  0.2666,  1.2331,  3.3903,  3.9754, -1.6672,  0.1581,  3.9603,
        -3.2824, -0.1087, -0.0310,  4.2102,  0.4083,  2.4512,  2.9878,  1.8994,
        -0.8072,  1.0338, -1.9971, -1.4553, -1.8671,  2.2586, -1.5754,  2.1126,
        -2.4074,  0.0528, -0.7830,  0.1039,  0.0303, -0.6595,  2.0623, -2.1856,
        -1.9411,  1.3825,  1.0632, -2.2670, -3.0951,  2.3701,  0.8550, -0.8052,
         0.8322, -1.3764,  0.1121, -0.6793,  0.5584, -0.6518, -1.1550,  0.1042,
         0.0862, -0.2729,  0.6178, -1.8404, -0.8232,  3.1421, -0.6792,  6.1117,
        -3.9787, -2.4870, -0.8516, -3.2177,  2.6562, -2.6821, -2.0679,  1.2958,
         1.2117,  1.6112, -0.5183,  0.2246,  0.9165,  4.1118, -1.7985, -0.0810,
         1.4875, -1.6773, -1.4985,  1.5118,  0.7076,  2.1149, -1.3244, -1.3417])

dalchan = torch.tensor([-0.1452,  3.4995, -1.3931,  4.0207,  1.6986, -1.8153, -1.8049, -3.1622,
        -1.9226,  0.3184, -0.8791,  0.2171, -2.6286, -1.8944,  1.2933, -2.4037,
        -0.1537, -0.8781, -1.5620,  2.4296,  1.3568,  5.0106,  2.2176,  0.4446,
        -0.9780,  0.5583, -1.8897,  3.9957, -0.7461,  9.8770,  1.3354,  1.0288,
         0.3971, -2.0116, -1.8326, -3.0421, -0.6936,  1.5896, -0.7049, -1.7085,
         3.8035, -0.3393, -1.2809,  2.3341,  3.0266,  0.1051, -0.2176, -1.0173,
        -3.7906, -2.1645,  0.0357, -1.8600, -4.0265, -1.7367,  4.0771,  0.6777,
        -0.3157,  2.7762, -1.4047, -0.6234, -1.3524, -0.0568, -1.2097,  0.7029,
        -1.2471,  3.7257,  0.0796, -1.6533,  1.1200,  2.0286,  4.2183, -0.7076,
         1.7333, -1.5534, -0.3738, -1.0356, -0.5094, -0.1901,  2.0325, -2.1256,
         1.2354,  0.9579,  2.7707,  1.2127,  1.5030,  0.0612, -3.6441, -0.1684,
        -0.9642, -0.8786, -0.6822, -2.4483, -0.6959,  1.3301,  2.2819, -0.0949,
        -2.5849, -3.2252, -0.7059, -1.8507,  1.3961, -0.7782, -1.0514, -1.7795,
        -2.5253,  1.5683, -2.0661, -2.0564,  0.8318, -0.2200, -3.4123, -0.5530,
        -0.3540, -1.4213, -0.5838, -1.9922,  0.2668,  0.0569,  3.9190, -1.7095])

chiwapug = torch.tensor([-1.6535, -0.1950,  0.3875,  1.4274,  0.9036, -1.4943, -2.5997, -1.9144,
        -1.0155, -2.1878,  3.3686,  3.2179, -3.4971,  7.0463, -0.9941, -0.0393,
         2.0601,  6.1839, -1.1973, -0.3065, -1.4193, -1.2251, -2.6873,  0.3496,
         2.0388,  3.8097,  3.7084, -1.7241, -1.3501, -0.5458, -0.8647,  0.3087,
        -1.4715, -1.2350, -0.3732, -2.0021, -0.9384, -0.5491, -0.1844, -2.1417,
         4.1946,  0.7010,  1.3860,  0.0257, -1.9448, -0.9698, -1.6128, -0.6900,
         1.7793,  0.3289, -3.3940,  3.6030,  0.7535,  0.0134,  1.5922,  3.1951,
         0.0970,  0.9318, -2.1343, -1.8123, -3.2404, -2.1339, -3.4140, -0.2481,
         0.1095,  2.0692, -0.4178,  2.0409, -3.3741, -0.7393,  0.0351, -2.1578,
        -3.0193, -1.5581, -0.7260, -1.2128, -1.6087,  1.8557,  0.7724,  2.7725,
         1.9039, -1.6183,  2.3392, -1.5116,  5.1190, -0.9662,  2.2682, -1.1147,
         1.8447, -0.3112, -0.8793,  0.9854,  3.7755, -0.6680, -1.4677,  3.2746,
        -2.9424, -1.8837,  4.4526, -3.6610,  0.1939,  0.0487,  4.1093,  3.8003,
        -1.6873, -0.8602, -1.3811, -3.4988,  6.2547,  2.0206,  0.4126, -1.5573,
        -1.1288, -2.0796, -0.7080, -1.9003,  2.0982,  0.6119, -1.3961, -2.4858])

aurora = torch.tensor([-3.0266,  0.1266, -2.7062,  0.7422,  0.3204, -3.2239, -2.2129,  1.1955,
         1.6484,  2.3599,  1.5537,  3.1902, -3.4925,  0.0306,  2.2346,  4.7372,
         1.6350,  3.0916, -2.0290, -4.6521, -0.7389,  2.0718,  2.1189, -1.3467,
         3.6523,  2.3778,  0.2619, -0.4465, -5.5514, -1.3133,  4.3920,  0.4614,
        -2.2979, -2.7437, -0.9293, -4.0388,  0.5517,  0.8555,  0.4481, -2.3940,
         3.3665, -0.7316,  0.9221,  1.9416, -0.6287, -1.9067,  1.1724,  0.8765,
         3.7218, -1.1146, -0.5492,  3.8424,  3.9393,  0.0488, -2.6585, -1.6892,
         5.2151, -0.9198,  0.9682, -1.5556, -2.2496, -1.6025, -0.2794,  2.3185,
         4.9061,  0.6197, -1.3327, -0.3614, -0.9805,  0.9916, -1.0160,  0.7080,
        -0.3167, -3.2962, -2.7182, -2.4129,  0.9838,  4.3959, -4.2066, -1.2743,
         0.7647,  1.7656,  0.4665, -1.4773, -0.5575,  0.2378, -0.2784,  0.2137,
         1.9714,  0.5218, -1.6104, -2.1568, -0.4101, -0.2225, -1.8161,  2.3191,
        -3.9176,  0.9633, -0.5760, -3.1944,  3.2666,  4.0593, -0.3701, -2.2716,
        -2.2947,  1.2959, -2.4052,  0.8878,  4.1030, -0.5938,  0.3557, -1.7345,
         0.4253, -1.7948, -1.1245, -1.8928,  2.5626, -3.0782,  0.5593, -2.1725])

tosakun = torch.tensor([-0.7230, -1.3562, -1.6953,  5.4068,  0.3074, -1.1664, -1.4088, -3.3570,
        -2.4592, -2.7658,  0.4664,  0.7128, -2.0831,  1.3833, -2.0884, -0.8967,
         2.1566,  2.0484, -0.5578,  0.4864,  1.4959, -2.1831, -2.9052, -0.6442,
        -0.8877,  3.0251,  0.3386,  0.8360, -3.2006,  6.1935, -0.5797,  1.2170,
         2.1551, -2.2920,  0.4114, -2.2398, -0.4344,  1.2690, -2.8633, -1.5405,
         3.7803, -0.6006,  1.1018,  0.8141, -0.7307,  0.4124, -0.8429,  0.7223,
        -1.7796,  0.3913, -1.6236, -1.6715, -0.0298, -1.3672,  7.0297,  0.4479,
         0.3430,  0.4649, -2.0080, -0.2346, -2.0920, -0.5521, -2.3366, -2.0133,
        -1.5792,  3.3363,  1.0171, -1.1647, -0.0610,  1.2186,  4.0580, -2.4815,
        -0.8327, -1.2653, -1.9584,  2.1296,  1.8312,  1.9882,  0.0197,  4.7192,
        -0.4931, -3.1930,  5.9566,  0.4798,  8.1777, -0.0570,  0.4614, -0.5936,
        -0.2337, -1.1335, -1.3360, -0.4913,  3.3126, -1.5554,  0.7905,  1.7797,
        -2.9821, -3.2899,  0.7640, -2.8739, -1.0453, -1.4397,  2.4814,  0.6108,
        -2.3406,  0.0594, -1.1621, -3.8469,  1.5265,  4.5502, -2.8917, -0.6945,
        -0.5807, -1.6680, -0.6013, -2.4009, -0.7639,  5.4986,  3.0071, -2.0080])

mairo = torch.tensor([-5.5926e-01, -8.2569e-01, -3.1176e+00, -2.7304e+00,  6.4241e-01,
         1.0438e+00, -2.2495e+00,  3.8212e-01,  3.6414e+00,  4.0185e+00,
        -3.1079e-01,  1.3325e+00, -3.3114e+00, -9.3996e-01,  1.5880e+00,
         2.9456e+00, -3.2262e+00,  7.8470e+00, -2.2496e-01, -3.3628e+00,
        -2.4686e+00,  2.7021e+00,  1.7739e+00, -2.2193e+00,  1.7886e+00,
         8.6303e-02, -2.6474e+00, -2.2266e+00, -2.8172e+00, -2.9391e+00,
         2.7565e-01, -2.3332e+00, -7.7620e-03, -1.0733e+00, -1.0432e+00,
        -3.4572e+00, -9.2455e-01,  3.0225e+00,  4.2322e+00, -2.4815e+00,
        -1.1945e+00, -1.7050e+00, -2.5116e+00,  2.8584e+00,  2.9408e+00,
         6.3569e-03, -1.4848e+00,  2.8758e+00, -3.6241e-01,  1.0493e+00,
        -4.6583e-01,  3.6672e+00,  4.7350e+00,  5.6747e+00, -3.4693e+00,
        -4.1877e+00, -1.4284e+00,  2.0772e+00, -1.1017e-01,  3.3883e-01,
        -6.2831e-01, -1.0343e+00,  3.6725e+00,  3.6740e+00,  3.2411e+00,
        -1.9875e+00, -1.4349e+00, -3.2572e+00,  1.8999e+00, -2.7020e+00,
        -1.1762e+00,  5.9931e-01,  1.3801e+00,  3.9024e+00,  7.8373e-01,
        -1.2376e+00, -1.8285e+00,  1.3145e+00, -4.8398e+00, -4.7887e+00,
        -9.7942e-01,  1.4340e+00, -2.9604e+00, -2.6698e-01, -5.2565e+00,
         1.0559e+00, -3.7936e+00, -1.1570e-01,  1.3118e+00,  2.0399e+00,
        -3.2096e+00, -9.2200e-01, -1.0616e+00, -8.1529e-01, -3.0452e+00,
        -1.4557e-01, -2.3269e+00,  1.3222e+00, -7.8489e-01, -2.6244e+00,
        -1.4842e+00,  3.1854e+00, -2.9681e+00,  1.6519e+00,  1.6371e-01,
         4.3297e+00, -1.9731e+00,  9.5248e+00, -2.8863e-01, -2.5275e+00,
         1.3849e+00,  3.0882e+00, -1.5362e+00, -2.2352e+00, -2.1705e-01,
         1.9321e+00,  6.2059e+00, -2.7010e+00,  5.1463e-01, -6.6730e-02])

pechi = torch.tensor([-2.7959,  0.9315, -3.0013,  2.1227, -1.5022,  0.8613, -2.2052, -1.2328,
         3.5818, -0.8001, -1.5079,  7.5157, -3.6412,  4.2507, -0.9043,  3.8904,
        -2.6844,  7.4292,  1.0225, -2.7123, -2.1305, -0.6524, -0.6415, -0.9186,
         0.9067,  9.6216,  0.0167, -3.1033, -3.4589, -1.0740,  0.2492, -1.1164,
        -0.3107, -2.9255, -1.7248, -2.9761, -2.8711,  1.3018,  4.7108, -1.8648,
         1.7226, -0.9956, -2.2271,  1.6549, -0.1272,  1.2728, -0.2354, -0.4969,
         0.9321,  0.3976, -2.6297,  6.4469,  3.4303,  1.7814, -1.8505, -2.3282,
         1.8090, -1.3280,  0.1125,  1.3326, -3.2386,  1.2385, -1.9519,  2.4747,
         0.3932,  2.9543, -0.1146, -0.7607, -2.0203, -1.2512, -1.3667, -1.5049,
         0.5150, -0.8168,  1.2167,  1.0595,  0.6193,  1.6722, -3.1961, -0.9278,
        -1.8506, -1.1721,  3.4422, -2.1160,  2.4588,  1.0029,  2.4132,  2.0909,
         3.1409,  0.0709, -2.6286, -0.9391,  2.9525, -2.3380, -2.9971,  1.1545,
        -3.0763, -0.4196,  1.1503, -2.6296,  0.4593,  0.2743, -0.5834,  0.9348,
        -0.5425,  0.7801, -2.7933, -0.2937,  5.9838, -1.1933,  0.6375, -1.4381,
        -1.9912, -1.0233, -0.7571, -0.2736,  3.3000, -2.8646,  0.0416, -0.8820])

IMG_MEAN = [0.485, 0.456, 0.406]
IMG_STD = [0.229, 0.224, 0.225]

gz = ["750px-Shiba_Inu.jpg", "1599px-Jack_Russell_Terrier_2.jpg", "dog_img_1_zadyrqo88zk8.jpg", "640px-Wasao.jpg", "630px-Fawn_pug_2.5year-old.JPG", "chiwax.jpg","dalmatian.jpg", "pawawa01.jpg", "aurora.jpeg", "tosa.jpg","mairo.jpeg","pechi.jpeg"]
taisho = ["shiba", "jack", "marupu", "wasao", "puu", "chiwax", "dalchan", "chiwapug", "aurora", "tosakun", "mairo","pechi"]
inu = {"shiba":shiba, "jack":jack, "marupu":marupu, "wasao":wasao, "puu":puu, "chiwax":chiwax, "dalchan":dalchan, "chiwapug":chiwapug, "aurora":aurora, "tosakun":tosakun, "mairo":mairo, "pechi":pechi}
num = []
atai = []

def hikaku(x):
    cos = nn.CosineSimilarity(dim=0, eps=1e-6)
    d = {k[0]: cos(x,k[1]).item() for k in zip(inu.keys(),inu.values())}
    li = []
    for i in d.values():
        #e = abs(i)
        li.append(i)
    idx = li.index(max(li))
    return idx


def predict(path):
    model_ft = models.resnet18(pretrained=True)
    model_ft.fc = nn.Linear(512, 120)
    param = torch.load("breeds.pth", map_location=torch.device('cpu'))
    model_ft.load_state_dict(param)
    transform = transforms.Compose([transforms.Resize(300), transforms.ToTensor(),transforms.Normalize(IMG_MEAN, IMG_STD)])
    #path = Image.open(path)
    inputs = transform(path)
    input = torch.unsqueeze(inputs, 0)
    model_ft.eval()
    outputs = model_ft(input)
    nirudog = hikaku(outputs[0])
    _, preds = torch.max(outputs.data, 1)
    img =  Image.open(gz[nirudog])
    label = taisho[nirudog]
    return class_names[preds],img,label,outputs[0]

# ans = predict("pechi.jpeg")
# print(ans[2],ans[3])